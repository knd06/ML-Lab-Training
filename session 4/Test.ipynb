{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/miniconda3/envs/kAI/lib/python3.11/site-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "from generate import *\n",
    "from encode import *\n",
    "from DataReader import *\n",
    "from RNN import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: 0-alt.atheism\n",
      "Processing: 1-comp.graphics\n",
      "Processing: 2-comp.os.ms-windows.misc\n",
      "Processing: 3-comp.sys.ibm.pc.hardware\n",
      "Processing: 4-comp.sys.mac.hardware\n",
      "Processing: 5-comp.windows.x\n",
      "Processing: 6-misc.forsale\n",
      "Processing: 7-rec.autos\n",
      "Processing: 8-rec.motorcycles\n",
      "Processing: 9-rec.sport.baseball\n",
      "Processing: 10-rec.sport.hockey\n",
      "Processing: 11-sci.crypt\n",
      "Processing: 12-sci.electronics\n",
      "Processing: 13-sci.med\n",
      "Processing: 14-sci.space\n",
      "Processing: 15-soc.religion.christian\n",
      "Processing: 16-talk.politics.guns\n",
      "Processing: 17-talk.politics.mideast\n",
      "Processing: 18-talk.politics.misc\n",
      "Processing: 19-talk.religion.misc\n",
      "Processing: 0-alt.atheism\n",
      "Processing: 1-comp.graphics\n",
      "Processing: 2-comp.os.ms-windows.misc\n",
      "Processing: 3-comp.sys.ibm.pc.hardware\n",
      "Processing: 4-comp.sys.mac.hardware\n",
      "Processing: 5-comp.windows.x\n",
      "Processing: 6-misc.forsale\n",
      "Processing: 7-rec.autos\n",
      "Processing: 8-rec.motorcycles\n",
      "Processing: 9-rec.sport.baseball\n",
      "Processing: 10-rec.sport.hockey\n",
      "Processing: 11-sci.crypt\n",
      "Processing: 12-sci.electronics\n",
      "Processing: 13-sci.med\n",
      "Processing: 14-sci.space\n",
      "Processing: 15-soc.religion.christian\n",
      "Processing: 16-talk.politics.guns\n",
      "Processing: 17-talk.politics.mideast\n",
      "Processing: 18-talk.politics.misc\n",
      "Processing: 19-talk.religion.misc\n"
     ]
    }
   ],
   "source": [
    "gen_data_and_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "encode_data('w2v/20news-train-raw.txt', 'w2v/vocab-raw.txt')\n",
    "encode_data('w2v/20news-test-raw.txt', 'w2v/vocab-raw.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_RNN():\n",
    "    with open('w2v/vocab-raw.txt') as f:\n",
    "        vocab_size = len(f.read().splitlines())\n",
    "    tf.set_random_seed(2024)\n",
    "\n",
    "    rnn = RNN(\n",
    "        vocab_size=vocab_size,\n",
    "        embedding_size=300,\n",
    "        lstm_size=50,\n",
    "        batch_size=50\n",
    "    )\n",
    "    predicted_labels, loss = rnn.build_graph()\n",
    "    train_op = rnn.trainer(loss=loss, learning_rate=0.01)\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        train_data_reader = DataReader(\n",
    "            data_path='w2v/20news-train-encoded.txt',\n",
    "            batch_size=50\n",
    "        )\n",
    "        test_data_reader = DataReader(\n",
    "            data_path='w2v/20news-test-encoded.txt',\n",
    "            batch_size=50\n",
    "        )\n",
    "        step = 0\n",
    "        MAX_STEP = 1000\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        while step < MAX_STEP:\n",
    "            next_train_batch = train_data_reader.next_batch()\n",
    "            train_data, train_labels, train_sentence_lengths, train_final_tokens = next_train_batch\n",
    "            plabels_eval, loss_eval, _ = sess.run(\n",
    "                [predicted_labels, loss, train_op],\n",
    "                feed_dict={\n",
    "                    rnn._data: train_data,\n",
    "                    rnn._labels: train_labels,\n",
    "                    rnn._sentence_lengths: train_sentence_lengths,\n",
    "                    rnn._final_tokens: train_final_tokens\n",
    "                }\n",
    "            )\n",
    "            step += 1\n",
    "            if step % 20 == 0:\n",
    "                print(f'loss : {loss_eval}')\n",
    "\n",
    "            if train_data_reader._batch_id == 0:\n",
    "                num_true_preds = 0\n",
    "                while True:\n",
    "                    next_test_batch = test_data_reader.next_batch()\n",
    "                    test_data, test_labels, test_sentence_lengths, test_final_tokens = next_test_batch\n",
    "                    test_plabels_eval = sess.run(\n",
    "                        predicted_labels,\n",
    "                        feed_dict={\n",
    "                            rnn._data: test_data,\n",
    "                            rnn._labels: test_labels,\n",
    "                            rnn._sentence_lengths: test_sentence_lengths,\n",
    "                            rnn._final_tokens: test_final_tokens\n",
    "                        }\n",
    "                    )\n",
    "                    \n",
    "                    matches = np.equal(test_plabels_eval, test_labels)\n",
    "                    num_true_preds += np.sum(matches.astype(float))\n",
    "                    if test_data_reader._batch_id == 0:\n",
    "                        break\n",
    "                    \n",
    "                print(f'Epoch: {train_data_reader._num_epoch}')\n",
    "                print(f'Accuracy on test data: {num_true_preds * 100. / len(test_data_reader._data)}')\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/dayo/Documents/ML-Lab-Training/session 4/RNN.py:41: static_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell, unroll=True)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /opt/miniconda3/envs/kAI/lib/python3.11/site-packages/keras/layers/rnn/legacy_cells.py:792: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dayo/Documents/ML-Lab-Training/session 4/RNN.py:33: UserWarning: `tf.nn.rnn_cell.BasicLSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n",
      "  lstm_cell = tf.nn.rnn_cell.BasicLSTMCell(self._lstm_size)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/miniconda3/envs/kAI/lib/python3.11/site-packages/tensorflow/python/util/dispatch.py:1176: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-16 17:15:56.662821: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:353] MLIR V1 optimization pass is not enabled\n",
      "2024-11-16 17:15:57.312619: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : 7.144278060877696e-05\n",
      "loss : 0.06548171490430832\n",
      "loss : 8.959388732910156\n",
      "loss : 0.01862339675426483\n",
      "loss : 0.38219165802001953\n",
      "loss : 5.000552177429199\n",
      "loss : 2.5724804401397705\n",
      "loss : 0.7893913984298706\n",
      "loss : 4.1125712394714355\n",
      "loss : 4.122959136962891\n",
      "loss : 6.1617913246154785\n",
      "Epoch: 1\n",
      "Accuracy on test data: 8.47052575677111\n",
      "loss : 2.945035696029663\n",
      "loss : 2.304654359817505\n",
      "loss : 2.212629795074463\n",
      "loss : 1.8416088819503784\n",
      "loss : 1.8866755962371826\n",
      "loss : 1.7693623304367065\n",
      "loss : 1.6243418455123901\n",
      "loss : 1.565423846244812\n",
      "loss : 1.4383996725082397\n",
      "loss : 1.4029066562652588\n",
      "loss : 1.3367342948913574\n",
      "Epoch: 2\n",
      "Accuracy on test data: 71.0833775889538\n",
      "loss : 1.0192599296569824\n",
      "loss : 0.926663339138031\n",
      "loss : 0.9314233660697937\n",
      "loss : 0.8637201189994812\n",
      "loss : 0.8783875107765198\n",
      "loss : 0.635991096496582\n",
      "loss : 0.6612381935119629\n",
      "loss : 0.606234610080719\n",
      "loss : 0.5575686693191528\n",
      "loss : 0.4075246751308441\n",
      "loss : 0.5308899879455566\n",
      "Epoch: 3\n",
      "Accuracy on test data: 74.46893255443442\n",
      "loss : 0.21554093062877655\n",
      "loss : 0.32386767864227295\n",
      "loss : 0.33306068181991577\n",
      "loss : 0.3821708559989929\n",
      "loss : 0.2691997289657593\n",
      "loss : 0.33420702815055847\n",
      "loss : 0.2420300841331482\n",
      "loss : 0.21009835600852966\n",
      "loss : 0.3572549521923065\n",
      "loss : 0.2584432363510132\n",
      "loss : 0.16328325867652893\n",
      "loss : 0.1487467885017395\n",
      "Epoch: 4\n",
      "Accuracy on test data: 76.04885820499203\n",
      "loss : 0.04801231250166893\n",
      "loss : 0.07290833443403244\n",
      "loss : 0.07736466079950333\n",
      "loss : 0.06697488576173782\n",
      "loss : 0.055043719708919525\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_RNN()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
